{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d30187fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>D</th>\n",
       "      <th>treshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  D  treshold\n",
       "0  1  0  1         0\n",
       "1  1  0  2         1\n",
       "2  1  0  3         2\n",
       "3  2  5  4         0\n",
       "4  2  5  5         1\n",
       "5  3  6  6         0\n",
       "6  3  6  7         1\n",
       "7  3  6  8         2\n",
       "8  3  6  9         3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'dataset' holds the input data for this script\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.DataFrame({\"A\":[1, 1, 1, 2, 2, 3, 3, 3, 3]\n",
    "                        , \"B\":[0, 0, 0, 5, 5, 6, 6, 6, 6]\n",
    "                        , \"D\":[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "                        , \"treshold\":[0, 1, 2, 0, 1, 0, 1, 2, 3]})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bcd0c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>D</th>\n",
       "      <th>treshold</th>\n",
       "      <th>AuROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  D  treshold  AuROC\n",
       "0  1  0  1         0      6\n",
       "1  1  0  2         1      6\n",
       "2  1  0  3         2      6\n",
       "3  2  5  4         0      9\n",
       "4  2  5  5         1      9\n",
       "5  3  6  6         0     30\n",
       "6  3  6  7         1     30\n",
       "7  3  6  8         2     30\n",
       "8  3  6  9         3     30"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.sort_values(by=[\"A\", \"B\", \"treshold\"])\n",
    "\n",
    "dataset[\"AuROC\"] = 0\n",
    "\n",
    "for i in np.arange(dataset.shape[0]):\n",
    "    if dataset.loc[i, \"treshold\"] == 0:\n",
    "        dataset.loc[i, \"AuROC\"] = dataset.loc[i, \"D\"]\n",
    "    else:\n",
    "        dataset.loc[i, \"AuROC\"] = dataset.loc[i-1, \"AuROC\"] + dataset.loc[i, \"D\"]\n",
    "\n",
    "dataset[\"AuROC\"] = dataset.join(dataset.groupby(by=[\"A\", \"B\"])[\"AuROC\"].max(), on=[\"A\", \"B\"], lsuffix='_acum')[\"AuROC\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cbb402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import math\n",
    "import librosa\n",
    "import heartpy as hp\n",
    "import datetime\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae1518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, TensorBoard, ReduceLROnPlateau,\n",
    "                                        CSVLogger, EarlyStopping)\n",
    "from csv import writer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a0b1504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af0be5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_dataset import create_dataset\n",
    "from callback_save_files import TrainingCallback, FitCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0ce2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIRECTORY = 'C:/CVUT/Diplomka/'\n",
    "logs_dir = f'{WORKING_DIRECTORY}Data/logs/'\n",
    "file_name = '20231203 Channel-desease dependency'\n",
    "task_name = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4210780a",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c58a9b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_filepath = f'{WORKING_DIRECTORY}Data/CODE-15/val'\n",
    "train_filepath = f'{WORKING_DIRECTORY}Data/CODE-15/train'\n",
    "\n",
    "val_Y = create_dataset('val_Y', val_filepath,0)\n",
    "val_F_X = create_dataset('val_I_F_X_m', val_filepath,0)\n",
    "\n",
    "val_dataset = tf.data.Dataset.zip((val_F_X, val_Y))\n",
    "\n",
    "train_Y = create_dataset('train_Y', train_filepath,0)\n",
    "train_F_X = create_dataset('train_I_F_X_m', train_filepath,0)\n",
    "\n",
    "train_dataset = tf.data.Dataset.zip((train_F_X, train_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59d91db",
   "metadata": {},
   "source": [
    "Undersampling for speed improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "822f4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_undersampling = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fb1b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def random_undersampling(x, y):\n",
    "    return tf.random.uniform((1, 1), 0, 1)[0, 0] < rate_undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "525bfb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x0000021BA003CEE0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x0000021BA003CEE0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x, y: tf.reduce_sum(y) > 0\n",
      "\n",
      "Match 1:\n",
      "lambda x, y: tf.reduce_sum(y) == 0\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x0000021BA003CEE0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x0000021BA003CEE0>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x, y: tf.reduce_sum(y) > 0\n",
      "\n",
      "Match 1:\n",
      "lambda x, y: tf.reduce_sum(y) == 0\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x0000021BA0162040> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x0000021BA0162040>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x, y: tf.reduce_sum(y) > 0\n",
      "\n",
      "Match 1:\n",
      "lambda x, y: tf.reduce_sum(y) == 0\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x0000021BA0162040> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x0000021BA0162040>: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names. The matching definitions were:\n",
      "Match 0:\n",
      "lambda x, y: tf.reduce_sum(y) > 0\n",
      "\n",
      "Match 1:\n",
      "lambda x, y: tf.reduce_sum(y) == 0\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "short_train_dataset = train_dataset.filter(lambda x, y: tf.reduce_sum(y)==0).filter(random_undersampling).concatenate(train_dataset.filter(lambda x, y: tf.reduce_sum(y)>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08787e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_train_dataset = short_train_dataset.shuffle(short_train_dataset.cardinality(), reshuffle_each_iteration  = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feb47275",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9bc3c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_count = 0\n",
    "for inst in short_train_dataset:\n",
    "    inst_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92b524f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2724"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccae681",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16aaadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34cefcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_ZipDataset element_spec=(TensorSpec(shape=(500, 12), dtype=tf.float64, name=None), TensorSpec(shape=(6,), dtype=tf.float64, name=None))>\n",
      "Epoch 1/70\n",
      "340/340 [==============================] - 4s 7ms/step - loss: 4.8770 - binary_accuracy: 0.8704 - precision: 0.3671 - recall: 0.3891 - f1_score: 0.3717 - val_loss: 0.3356 - val_binary_accuracy: 0.9620 - val_precision: 0.2060 - val_recall: 0.2929 - val_f1_score: 0.0973 - lr: 0.0010\n",
      "Epoch 2/70\n",
      "340/340 [==============================] - 4s 12ms/step - loss: 0.6895 - binary_accuracy: 0.8941 - precision: 0.4879 - recall: 0.4673 - f1_score: 0.4366 - val_loss: 0.2694 - val_binary_accuracy: 0.9374 - val_precision: 0.1577 - val_recall: 0.4667 - val_f1_score: 0.1299 - lr: 0.0010\n",
      "Epoch 3/70\n",
      "340/340 [==============================] - 2s 7ms/step - loss: 0.5347 - binary_accuracy: 0.9004 - precision: 0.5007 - recall: 0.4662 - f1_score: 0.4255 - val_loss: 0.2338 - val_binary_accuracy: 0.9389 - val_precision: 0.1750 - val_recall: 0.5253 - val_f1_score: 0.1374 - lr: 0.0010\n",
      "Epoch 4/70\n",
      "340/340 [==============================] - 3s 10ms/step - loss: 0.6675 - binary_accuracy: 0.8975 - precision: 0.4869 - recall: 0.4656 - f1_score: 0.4346 - val_loss: 0.2618 - val_binary_accuracy: 0.9528 - val_precision: 0.1958 - val_recall: 0.4121 - val_f1_score: 0.1259 - lr: 0.0010\n",
      "Epoch 5/70\n",
      "340/340 [==============================] - 3s 9ms/step - loss: 0.9939 - binary_accuracy: 0.8901 - precision: 0.4549 - recall: 0.4576 - f1_score: 0.4149 - val_loss: 0.2526 - val_binary_accuracy: 0.9582 - val_precision: 0.2201 - val_recall: 0.4020 - val_f1_score: 0.1079 - lr: 0.0010\n",
      "Epoch 6/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.4239 - binary_accuracy: 0.9096 - precision: 0.5547 - recall: 0.5161 - f1_score: 0.4866 - val_loss: 0.1445 - val_binary_accuracy: 0.9634 - val_precision: 0.2490 - val_recall: 0.3818 - val_f1_score: 0.1249 - lr: 0.0010\n",
      "Epoch 7/70\n",
      "340/340 [==============================] - 3s 10ms/step - loss: 0.4689 - binary_accuracy: 0.9101 - precision: 0.5598 - recall: 0.5040 - f1_score: 0.4764 - val_loss: 0.2239 - val_binary_accuracy: 0.9626 - val_precision: 0.2175 - val_recall: 0.3111 - val_f1_score: 0.1062 - lr: 0.0010\n",
      "Epoch 8/70\n",
      "340/340 [==============================] - 3s 9ms/step - loss: 0.5296 - binary_accuracy: 0.9049 - precision: 0.5273 - recall: 0.5083 - f1_score: 0.4632 - val_loss: 0.4363 - val_binary_accuracy: 0.9416 - val_precision: 0.1613 - val_recall: 0.4343 - val_f1_score: 0.1187 - lr: 0.0010\n",
      "Epoch 9/70\n",
      "340/340 [==============================] - 3s 9ms/step - loss: 0.7882 - binary_accuracy: 0.8958 - precision: 0.4931 - recall: 0.4905 - f1_score: 0.4508 - val_loss: 0.1930 - val_binary_accuracy: 0.9681 - val_precision: 0.2669 - val_recall: 0.3111 - val_f1_score: 0.1239 - lr: 0.0010\n",
      "Epoch 10/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.3635 - binary_accuracy: 0.9140 - precision: 0.5796 - recall: 0.5040 - f1_score: 0.4930 - val_loss: 0.1429 - val_binary_accuracy: 0.9675 - val_precision: 0.2964 - val_recall: 0.4162 - val_f1_score: 0.1374 - lr: 0.0010\n",
      "Epoch 11/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.2197 - binary_accuracy: 0.9301 - precision: 0.6847 - recall: 0.5586 - f1_score: 0.5465 - val_loss: 0.1459 - val_binary_accuracy: 0.9610 - val_precision: 0.2402 - val_recall: 0.4081 - val_f1_score: 0.1316 - lr: 0.0010\n",
      "Epoch 12/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.2114 - binary_accuracy: 0.9344 - precision: 0.7160 - recall: 0.5797 - f1_score: 0.5412 - val_loss: 0.1864 - val_binary_accuracy: 0.9457 - val_precision: 0.1779 - val_recall: 0.4485 - val_f1_score: 0.1272 - lr: 0.0010\n",
      "Epoch 13/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.2731 - binary_accuracy: 0.9236 - precision: 0.6438 - recall: 0.5390 - f1_score: 0.5226 - val_loss: 0.1732 - val_binary_accuracy: 0.9541 - val_precision: 0.2148 - val_recall: 0.4586 - val_f1_score: 0.1281 - lr: 0.0010\n",
      "Epoch 14/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.2900 - binary_accuracy: 0.9213 - precision: 0.6298 - recall: 0.5576 - f1_score: 0.5258 - val_loss: 0.1535 - val_binary_accuracy: 0.9721 - val_precision: 0.3021 - val_recall: 0.2667 - val_f1_score: 0.1232 - lr: 0.0010\n",
      "Epoch 15/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.2907 - binary_accuracy: 0.9227 - precision: 0.6318 - recall: 0.5495 - f1_score: 0.5136 - val_loss: 0.2001 - val_binary_accuracy: 0.9475 - val_precision: 0.1658 - val_recall: 0.3818 - val_f1_score: 0.1156 - lr: 0.0010\n",
      "Epoch 16/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.2529 - binary_accuracy: 0.9246 - precision: 0.6520 - recall: 0.5476 - f1_score: 0.5353 - val_loss: 0.1981 - val_binary_accuracy: 0.9291 - val_precision: 0.1327 - val_recall: 0.4384 - val_f1_score: 0.1169 - lr: 0.0010\n",
      "Epoch 17/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.1259 - binary_accuracy: 0.9547 - precision: 0.8486 - recall: 0.6599 - f1_score: 0.5960 - val_loss: 0.1229 - val_binary_accuracy: 0.9674 - val_precision: 0.3057 - val_recall: 0.4545 - val_f1_score: 0.1410 - lr: 1.0000e-04\n",
      "Epoch 18/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.1150 - binary_accuracy: 0.9572 - precision: 0.8606 - recall: 0.6725 - f1_score: 0.6078 - val_loss: 0.1057 - val_binary_accuracy: 0.9727 - val_precision: 0.3624 - val_recall: 0.4202 - val_f1_score: 0.1432 - lr: 1.0000e-04\n",
      "Epoch 19/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.1194 - binary_accuracy: 0.9556 - precision: 0.8625 - recall: 0.6671 - f1_score: 0.6185 - val_loss: 0.1132 - val_binary_accuracy: 0.9692 - val_precision: 0.3215 - val_recall: 0.4404 - val_f1_score: 0.1401 - lr: 1.0000e-04\n",
      "Epoch 20/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.1117 - binary_accuracy: 0.9587 - precision: 0.8742 - recall: 0.6900 - f1_score: 0.6181 - val_loss: 0.1101 - val_binary_accuracy: 0.9697 - val_precision: 0.3230 - val_recall: 0.4222 - val_f1_score: 0.1406 - lr: 1.0000e-04\n",
      "Epoch 21/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.1096 - binary_accuracy: 0.9587 - precision: 0.8704 - recall: 0.6942 - f1_score: 0.6216 - val_loss: 0.1053 - val_binary_accuracy: 0.9713 - val_precision: 0.3421 - val_recall: 0.4202 - val_f1_score: 0.1446 - lr: 1.0000e-04\n",
      "Epoch 22/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.1111 - binary_accuracy: 0.9566 - precision: 0.8695 - recall: 0.6749 - f1_score: 0.6182 - val_loss: 0.1127 - val_binary_accuracy: 0.9692 - val_precision: 0.3102 - val_recall: 0.3980 - val_f1_score: 0.1397 - lr: 1.0000e-04\n",
      "Epoch 23/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.1089 - binary_accuracy: 0.9592 - precision: 0.8680 - recall: 0.7046 - f1_score: 0.6264 - val_loss: 0.1304 - val_binary_accuracy: 0.9609 - val_precision: 0.2494 - val_recall: 0.4424 - val_f1_score: 0.1410 - lr: 1.0000e-04\n",
      "Epoch 24/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.1057 - binary_accuracy: 0.9595 - precision: 0.8637 - recall: 0.6941 - f1_score: 0.6086 - val_loss: 0.1135 - val_binary_accuracy: 0.9693 - val_precision: 0.3224 - val_recall: 0.4384 - val_f1_score: 0.1388 - lr: 1.0000e-04\n",
      "Epoch 25/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.1059 - binary_accuracy: 0.9599 - precision: 0.8719 - recall: 0.7034 - f1_score: 0.6236 - val_loss: 0.1226 - val_binary_accuracy: 0.9657 - val_precision: 0.2926 - val_recall: 0.4646 - val_f1_score: 0.1388 - lr: 1.0000e-04\n",
      "Epoch 26/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.1032 - binary_accuracy: 0.9625 - precision: 0.8785 - recall: 0.7396 - f1_score: 0.6265 - val_loss: 0.1293 - val_binary_accuracy: 0.9646 - val_precision: 0.2895 - val_recall: 0.4889 - val_f1_score: 0.1419 - lr: 1.0000e-04\n",
      "Epoch 27/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.1059 - binary_accuracy: 0.9588 - precision: 0.8529 - recall: 0.7052 - f1_score: 0.6226 - val_loss: 0.1164 - val_binary_accuracy: 0.9697 - val_precision: 0.3214 - val_recall: 0.4182 - val_f1_score: 0.1410 - lr: 1.0000e-04\n",
      "Epoch 28/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.0911 - binary_accuracy: 0.9665 - precision: 0.8932 - recall: 0.7650 - f1_score: 0.6335 - val_loss: 0.1141 - val_binary_accuracy: 0.9706 - val_precision: 0.3354 - val_recall: 0.4283 - val_f1_score: 0.1406 - lr: 1.0000e-05\n",
      "Epoch 29/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.0945 - binary_accuracy: 0.9645 - precision: 0.8900 - recall: 0.7428 - f1_score: 0.6311 - val_loss: 0.1143 - val_binary_accuracy: 0.9696 - val_precision: 0.3242 - val_recall: 0.4323 - val_f1_score: 0.1428 - lr: 1.0000e-05\n",
      "Epoch 30/70\n",
      "340/340 [==============================] - 3s 9ms/step - loss: 0.0880 - binary_accuracy: 0.9687 - precision: 0.9026 - recall: 0.7657 - f1_score: 0.6252 - val_loss: 0.1101 - val_binary_accuracy: 0.9717 - val_precision: 0.3448 - val_recall: 0.4061 - val_f1_score: 0.1415 - lr: 1.0000e-05\n",
      "Epoch 31/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.0820 - binary_accuracy: 0.9704 - precision: 0.9114 - recall: 0.7808 - f1_score: 0.6383 - val_loss: 0.1117 - val_binary_accuracy: 0.9709 - val_precision: 0.3392 - val_recall: 0.4283 - val_f1_score: 0.1423 - lr: 1.0000e-05\n",
      "Epoch 32/70\n",
      "340/340 [==============================] - 3s 8ms/step - loss: 0.0871 - binary_accuracy: 0.9685 - precision: 0.9065 - recall: 0.7593 - f1_score: 0.6216 - val_loss: 0.1174 - val_binary_accuracy: 0.9686 - val_precision: 0.3124 - val_recall: 0.4323 - val_f1_score: 0.1401 - lr: 1.0000e-05\n",
      "499/499 [==============================] - 1s 1ms/step\n",
      "true_positive: 495.0\n",
      "Run started at 20231204 164028, i_best = 0, accuracy = 0.02069224981188864, f1 = 0.5999760751727837, tau_best_separated = [0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21be2929b50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        input_F_X = tf.keras.Input(shape=(500,12,), name='CNN_input_F_X')\n",
    "        Flat = tf.keras.layers.Flatten(name='Flat')(input_F_X)\n",
    "        D_1 = tf.keras.layers.Dense(120, activation = 'linear')(Flat)\n",
    "        D_2 = tf.keras.layers.Dense(90 , activation = 'linear')(D_1)\n",
    "        D_3 = tf.keras.layers.Dense(60 , activation = 'linear')(D_2)\n",
    "        D_4 = tf.keras.layers.Dense(30 , activation = 'linear')(D_3)\n",
    "        outputs = tf.keras.layers.Dense(6, activation='sigmoid')(D_4)\n",
    "        model = tf.keras.models.Model(inputs=input_F_X\n",
    "                                      , outputs=outputs)\n",
    "        #model.summary()\n",
    "\n",
    "        model.compile(loss=tf.keras.losses.BinaryCrossentropy() #'binary_crossentropy'\n",
    "                 , optimizer=tf.keras.optimizers.Adam(lr)\n",
    "                 , metrics=[tf.keras.metrics.BinaryAccuracy(name='binary_accuracy')\n",
    "                            , tf.keras.metrics.Precision(name='precision')\n",
    "                            , tf.keras.metrics.Recall(name='recall')\n",
    "                            , tf.keras.metrics.F1Score(name='f1_score', average='micro')])\n",
    "\n",
    "        # CALLBACKS\n",
    "        callbacks = [ReduceLROnPlateau(monitor='val_loss',\n",
    "                                           factor=0.1,\n",
    "                                           patience=6,\n",
    "                                           min_lr=lr / 100),\n",
    "                         EarlyStopping(patience=11,  # Patience should be larger than the one in ReduceLROnPlateau\n",
    "                                       min_delta=0.00001),\n",
    "                    FitCallback(logs_dir, file_name, val_dataset, 'All channels')\n",
    "                    ]\n",
    "\n",
    "        model.fit( short_train_dataset.batch(8).repeat(70),\n",
    "                epochs=70,\n",
    "                initial_epoch=0,\n",
    "                steps_per_epoch = np.floor(inst_count/8),\n",
    "                #batch_size = 8,\n",
    "                callbacks = callbacks,\n",
    "                #callbacks=[myCallback(init_vars)], \n",
    "                validation_data=(val_dataset.batch(8)),\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb0ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for channel in np.arange(12):\n",
    "    \n",
    "    task_name = f\"Channel {channel}\"\n",
    "    \n",
    "    for times in range(5):\n",
    "        input_F_X = tf.keras.Input(shape=(500,12,), name='CNN_input_F_X')\n",
    "        Get_elem = tf.keras.layers.Lambda(lambda x: x[:, :, channel])(input_F_X)\n",
    "        D_1 = tf.keras.layers.Dense(120, activation = 'linear')(Get_elem)\n",
    "        D_2 = tf.keras.layers.Dense(90 , activation = 'linear')(D_1)\n",
    "        D_3 = tf.keras.layers.Dense(60 , activation = 'linear')(D_2)\n",
    "        D_4 = tf.keras.layers.Dense(30 , activation = 'linear')(D_3)\n",
    "        outputs = tf.keras.layers.Dense(6, activation='sigmoid')(D_4)\n",
    "        model = tf.keras.models.Model(inputs=input_F_X\n",
    "                                      , outputs=outputs)\n",
    "        #model.summary()\n",
    "\n",
    "        model.compile(loss=tf.keras.losses.BinaryCrossentropy() #'binary_crossentropy'\n",
    "                 , optimizer=tf.keras.optimizers.Adam(lr)\n",
    "                 , metrics=[tf.keras.metrics.BinaryAccuracy(name='binary_accuracy')\n",
    "                            , tf.keras.metrics.Precision(name='precision')\n",
    "                            , tf.keras.metrics.Recall(name='recall')\n",
    "                            , tf.keras.metrics.F1Score(name='f1_score', average='micro')])\n",
    "\n",
    "        # CALLBACKS\n",
    "        callbacks = [ReduceLROnPlateau(monitor='val_loss',\n",
    "                                           factor=0.1,\n",
    "                                           patience=6,\n",
    "                                           min_lr=lr / 100),\n",
    "                         EarlyStopping(patience=11,  # Patience should be larger than the one in ReduceLROnPlateau\n",
    "                                       min_delta=0.00001),\n",
    "                    FitCallback(logs_dir, file_name, val_dataset, task_name)\n",
    "                    ]\n",
    "\n",
    "        model.fit( short_train_dataset.batch(8).repeat(70),\n",
    "                epochs=70,\n",
    "                initial_epoch=0,\n",
    "                steps_per_epoch = np.floor(inst_count/8),\n",
    "                #batch_size = 8,\n",
    "                callbacks = callbacks,\n",
    "                #callbacks=[myCallback(init_vars)], \n",
    "                validation_data=(val_dataset.batch(8)),\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_dataset = val_dataset.batch(11).take(1)\n",
    "\n",
    "print(model.evaluate(val_dataset.batch(11)))\n",
    "print(np.round(model.predict(mini_dataset ), 2))\n",
    "\n",
    "for inst in mini_dataset:\n",
    "    print(inst[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e7242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ca09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
