{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2767c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Exploration start.\n",
      "338\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import scipy\n",
    "import math\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, TensorBoard, ReduceLROnPlateau,\n",
    "                                        CSVLogger, EarlyStopping, TerminateOnNaN)\n",
    "from csv import writer\n",
    "from datetime import datetime\n",
    "\n",
    "from load_dataset import create_dataset, read_and_random_undersampling_dataset, hdf5_file_dataset\n",
    "from callback_save_files import TrainingCallback, FitCallback\n",
    "import local_settings\n",
    "\n",
    "WORKING_DIRECTORY = local_settings.WORKING_DIRECTORY #'/home/buliabog/Diploma/'\n",
    "logs_dir = f'{WORKING_DIRECTORY}Data/logs/'\n",
    "file_name = '20240406 Calc Scikit-learn clasifiers'\n",
    "task_name = ''\n",
    "\n",
    "logs_directory = os.path.join(logs_dir, file_name)\n",
    "metrics_file = os.path.join(logs_directory, 'f1.csv')\n",
    "\n",
    "\n",
    "val_filepath = f'{WORKING_DIRECTORY}Data/CODE-15/val'\n",
    "train_filepath = f'{WORKING_DIRECTORY}Data/CODE-15/train'\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, precision_recall_curve\n",
    "\n",
    "clasifiers = [#{'name': \"AdaBoost\"\n",
    "              #  , 'clasifier': AdaBoostClassifier(random_state=42)\n",
    "              #  , 'type': 'sklearn'},\n",
    "               {'name': \"MLP\"\n",
    "                , 'clasifier': MLPClassifier(hidden_layer_sizes=(50, 40, 30, 20), max_iter=1000, random_state=42)\n",
    "                , 'type': 'sklearn'},\n",
    "               {'name': \"Random Forest\"\n",
    "                , 'clasifier': RandomForestClassifier(\n",
    "                                    max_depth=15, n_estimators=50, max_features=1, random_state=42\n",
    "                                )\n",
    "                , 'type': 'sklearn'\n",
    "               },\n",
    "              # {'name': \"Decision Tree\"\n",
    "              #  , 'clasifier': DecisionTreeClassifier(max_depth=25, random_state=42)\n",
    "              #  , 'type': 'sklearn'},\n",
    "             #  {'name': \"Gaussian Process\"\n",
    "             #   , 'clasifier': GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42)\n",
    "             #   , 'type': 'sklearn'},\n",
    "               \n",
    "              ]\n",
    "\n",
    "import mdct\n",
    "\n",
    "def mdct_reshaped(x):\n",
    "    MDCT = np.nan_to_num(mdct.mdst(x), 0)\n",
    "    MDCT = MDCT[:128, :, :].reshape(128, -1)\n",
    "    mx = np.max(np.abs(MDCT))\n",
    "    if mx != 0:        \n",
    "        MDCT = MDCT / mx\n",
    "    return MDCT\n",
    "\n",
    "import pywt\n",
    "\n",
    "def wavelet_transformation(x):\n",
    "    DWT = []\n",
    "    for i in range(x.shape[-1]):\n",
    "        DWT.append(np.vstack(pywt.dwt(x[:, i], 'coif17')))\n",
    "    #DWT = np.concatenate(pywt.dwt(x, 'coif17'), axis=1)\n",
    "    DWT = np.vstack(DWT)\n",
    "    mx = np.max(np.abs(DWT))\n",
    "    if mx != 0:\n",
    "        DWT = DWT / mx\n",
    "    return DWT.T\n",
    "\n",
    "domeny = [\n",
    "    {'name': 'TimeDomain'\n",
    "     , 'full name' : \"\"\n",
    "     , 'dataset_type': 'TimeDomain'\n",
    "     , 'X_post_processing': None},\n",
    "    {'name': 'rFFT'\n",
    "     , 'full name' : \"Fast Fourier Transformation for real values\"\n",
    "     , 'dataset_type': 'ClassicFourieMagnitude'\n",
    "     , 'X_post_processing': None},\n",
    "    {'name': 'FFTwDW'\n",
    "     , 'full name' : \"Fast Fourier Transformation with Dynamic window\"\n",
    "     , 'dataset_type': 'ImprovedFourieMagnitude'\n",
    "     , 'X_post_processing': None},\n",
    "    {'name': 'MDCT'\n",
    "     , 'full name' : \"Modified discrete cosine transform\"\n",
    "     , 'dataset_type': 'TimeDomain'\n",
    "     , 'X_post_processing': {'function': mdct_reshaped, 'shape': (128, 108)}\n",
    "     , 'shape_X' : (4096, 12)}, \n",
    "    {'name': 'WT'\n",
    "     , 'full name' : \"Wavelet transform\"\n",
    "     , 'dataset_type': 'TimeDomain'\n",
    "     , 'X_post_processing': {'function': wavelet_transformation, 'shape': (2098, 24)}\n",
    "     , 'shape_X' : (4096, 12)},\n",
    "    #{'name': 'STFT-FD'\n",
    "    # , 'full name' : \"Short-Time Fourier Transform with the Window Size Fixed in the Frequency Domain\"\n",
    "    # , 'dataset_type': 'TimeDomain'\n",
    "    # , 'X_post_processing': {'function': STFT_FD, 'shape': (4096, 12*510)}}\n",
    "    ]\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "\n",
    "if not os.path.exists(logs_directory):\n",
    "            # create dir\n",
    "            os.mkdir(logs_directory) \n",
    "if not os.path.exists(metrics_file):\n",
    "    # create metrics_file\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        f.write( 'Clasifier;Domena;Task;Run;TrainDuration;TestType;F1;TP;FP;FN;TN\\n')\n",
    "\n",
    "print('Exploration start.')\n",
    "\n",
    "count_rows_done = 0\n",
    "#with open(metrics_file, 'r') as f:\n",
    "#    count_rows_done = (len(f.read().split('\\n'))-2)/2\n",
    "#print(count_rows_done)\n",
    "\n",
    "\n",
    "with open(metrics_file, 'r') as f:\n",
    "    rows_processed = f.read().split('\\n')\n",
    "    \n",
    "rows_processed_keys = [';'.join(r.split(';')[:4]) for r in rows_processed]\n",
    "count_rows_done = len(rows_processed_keys)\n",
    "print(count_rows_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69cadc7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (52934, 2098, 24) and (52934, 6)\n",
      "Train dataset is read\n",
      "Clasifier MLP, task 4, domena WT, run 2 start at 2024-04-26 22:03:55.251646.\n",
      "Shapes: (34581, 2098, 24) and (34581, 6)\n",
      "test dataset is read\n",
      "Shapes: (827, 2098, 24) and (827, 6)\n",
      "test gold standart is read\n",
      "Clasifier MLP, domena WT, task 4, train_duration 8873.20845, run 2: F1_test = 0.36346060898985016, F1_atest = 0.038461538461538464\n",
      "Shapes: (52934, 2098, 24) and (52934, 6)\n",
      "Train dataset is read\n",
      "Clasifier Random Forest, task 4, domena WT, run 2 start at 2024-04-27 00:49:50.474911.\n",
      "Shapes: (34581, 2098, 24) and (34581, 6)\n",
      "test dataset is read\n",
      "Shapes: (827, 2098, 24) and (827, 6)\n",
      "test gold standart is read\n",
      "Clasifier Random Forest, domena WT, task 4, train_duration 1264.732047, run 2: F1_test = 0.0, F1_atest = 0.0\n",
      "Shapes: (52934, 4096, 12) and (52934, 6)\n",
      "Train dataset is read\n",
      "Clasifier MLP, task 5, domena TimeDomain, run 2 start at 2024-04-27 01:21:00.570406.\n",
      "Shapes: (34581, 4096, 12) and (34581, 6)\n",
      "test dataset is read\n",
      "Shapes: (827, 4096, 12) and (827, 6)\n",
      "test gold standart is read\n",
      "Clasifier MLP, domena TimeDomain, task 5, train_duration 3906.844877, run 2: F1_test = 0.08148591971240264, F1_atest = 0.0\n",
      "Shapes: (52934, 4096, 12) and (52934, 6)\n",
      "Train dataset is read\n",
      "Clasifier Random Forest, task 5, domena TimeDomain, run 2 start at 2024-04-27 02:33:54.698181.\n",
      "Shapes: (34581, 4096, 12) and (34581, 6)\n",
      "test dataset is read\n",
      "Shapes: (827, 4096, 12) and (827, 6)\n",
      "test gold standart is read\n",
      "Clasifier Random Forest, domena TimeDomain, task 5, train_duration 1009.66781, run 2: F1_test = 0.0, F1_atest = 0.0\n",
      "Shapes: (52934, 500, 12) and (52934, 6)\n",
      "Train dataset is read\n",
      "Clasifier MLP, task 5, domena rFFT, run 2 start at 2024-04-27 02:53:14.910847.\n",
      "Shapes: (34581, 500, 12) and (34581, 6)\n",
      "test dataset is read\n",
      "Shapes: (827, 500, 12) and (827, 6)\n",
      "test gold standart is read\n",
      "Clasifier MLP, domena rFFT, task 5, train_duration 437.653425, run 2: F1_test = 0.0679177837354781, F1_atest = 0.0\n",
      "Shapes: (52934, 500, 12) and (52934, 6)\n",
      "Train dataset is read\n",
      "Clasifier Random Forest, task 5, domena rFFT, run 2 start at 2024-04-27 03:00:40.276995.\n",
      "Shapes: (34581, 500, 12) and (34581, 6)\n",
      "test dataset is read\n",
      "Shapes: (827, 500, 12) and (827, 6)\n",
      "test gold standart is read\n",
      "Clasifier Random Forest, domena rFFT, task 5, train_duration 3.013335, run 2: F1_test = 0.0, F1_atest = 0.0\n",
      "Shapes: (52934, 500, 12) and (52934, 6)\n",
      "Train dataset is read\n",
      "Clasifier MLP, task 5, domena FFTwDW, run 2 start at 2024-04-27 03:00:51.358604.\n",
      "Shapes: (34581, 500, 12) and (34581, 6)\n",
      "test dataset is read\n",
      "Shapes: (827, 500, 12) and (827, 6)\n",
      "test gold standart is read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_27184\\1199677289.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  atest_f1_array = np.nan_to_num(2 * atest_precision * atest_recall / (atest_precision + atest_recall))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasifier MLP, domena FFTwDW, task 5, train_duration 454.315415, run 2: F1_test = 0.43585933630510154, F1_atest = 0.0\n",
      "Shapes: (52934, 500, 12) and (52934, 6)\n",
      "Train dataset is read\n",
      "Clasifier Random Forest, task 5, domena FFTwDW, run 2 start at 2024-04-27 03:08:34.810715.\n",
      "Shapes: (34581, 500, 12) and (34581, 6)\n",
      "test dataset is read\n",
      "Shapes: (827, 500, 12) and (827, 6)\n",
      "test gold standart is read\n",
      "Clasifier Random Forest, domena FFTwDW, task 5, train_duration 3.322511, run 2: F1_test = 0.0, F1_atest = 0.0\n",
      "Shapes: (52934, 128, 108) and (52934, 6)\n",
      "Train dataset is read\n",
      "Clasifier MLP, task 5, domena MDCT, run 2 start at 2024-04-27 03:38:41.354929.\n",
      "Shapes: (34581, 128, 108) and (34581, 6)\n",
      "test dataset is read\n",
      "Shapes: (827, 128, 108) and (827, 6)\n",
      "test gold standart is read\n",
      "Clasifier MLP, domena MDCT, task 5, train_duration 357.27353, run 2: F1_test = 0.07119741100323625, F1_atest = 0.0\n",
      "Shapes: (52934, 128, 108) and (52934, 6)\n",
      "Train dataset is read\n",
      "Clasifier Random Forest, task 5, domena MDCT, run 2 start at 2024-04-27 04:22:24.501185.\n",
      "Shapes: (34581, 128, 108) and (34581, 6)\n",
      "test dataset is read\n",
      "Shapes: (827, 128, 108) and (827, 6)\n",
      "test gold standart is read\n",
      "Clasifier Random Forest, domena MDCT, task 5, train_duration 4.801871, run 2: F1_test = 0.0, F1_atest = 0.0\n",
      "Shapes: (52934, 2098, 24) and (52934, 6)\n",
      "Train dataset is read\n",
      "Clasifier MLP, task 5, domena WT, run 2 start at 2024-04-27 04:40:41.841642.\n",
      "Shapes: (34581, 2098, 24) and (34581, 6)\n",
      "test dataset is read\n",
      "Shapes: (827, 2098, 24) and (827, 6)\n",
      "test gold standart is read\n",
      "Clasifier MLP, domena WT, task 5, train_duration 7868.886611, run 2: F1_test = 0.0853932584269663, F1_atest = 0.0\n",
      "Shapes: (52934, 2098, 24) and (52934, 6)\n",
      "Train dataset is read\n",
      "Clasifier Random Forest, task 5, domena WT, run 2 start at 2024-04-27 07:07:14.137110.\n",
      "Shapes: (34581, 2098, 24) and (34581, 6)\n",
      "test dataset is read\n",
      "Shapes: (827, 2098, 24) and (827, 6)\n",
      "test gold standart is read\n",
      "Clasifier Random Forest, domena WT, task 5, train_duration 972.760944, run 2: F1_test = 0.0, F1_atest = 0.0\n"
     ]
    }
   ],
   "source": [
    "current_row = 0\n",
    "batch_size = 64\n",
    "for run in range(3):\n",
    "    for task in [1, 2, 0, 3, 4, 5]:\n",
    "        for domena in domeny: \n",
    "            \n",
    "\n",
    "            # val_Y = np.array(val_Y, dtype='float32')   \n",
    "\n",
    "            if 'X_post_processing' in domena.keys() and domena['X_post_processing'] is not None:\n",
    "                X_shape = domena['X_post_processing']['shape']\n",
    "            else:\n",
    "                X_shape = (4096, 12)  \n",
    "                \n",
    "            # iterate over classifierss\n",
    "            for clasifier in clasifiers:\n",
    "                cl_name = clasifier['name']\n",
    "                cl_type = clasifier['type']\n",
    "                dm_name= domena['name']\n",
    "                row_key = f\"{cl_name};{dm_name};{task};{run}\"\n",
    "                if row_key in rows_processed_keys:\n",
    "                    continue\n",
    "                try:\n",
    "                    del test_X\n",
    "                    del test_Y\n",
    "                except:\n",
    "                    pass\n",
    "                train_X, train_Y = read_and_random_undersampling_dataset(f'{WORKING_DIRECTORY}Data/CODE-15', 'train_US_ratio_1'\n",
    "                                                          #, file_num = file_number\n",
    "                                                          , dataset_type = domena['dataset_type']\n",
    "                                                          , undersampling = False\n",
    "                                                          , return_numpy_copy = True\n",
    "                                                          , X_post_processing = domena['X_post_processing']\n",
    "                                                        )\n",
    "\n",
    "                print('Train dataset is read')\n",
    "                train_Y = np.array(train_Y, dtype='float32')  \n",
    "                train_start_time = datetime.now()\n",
    "                print(f'Clasifier {cl_name}, task {task}, domena {dm_name}, run {run} start at {train_start_time}.')\n",
    "                clf = clasifier['clasifier']\n",
    "                \n",
    "                try:\n",
    "                    clf.fit(train_X, train_Y[:, task])\n",
    "                except: \n",
    "                    clf.fit(train_X.reshape(train_X.shape[0], -1), train_Y[:, task])\n",
    "\n",
    "                duration_delta = datetime.now() - train_start_time\n",
    "                \n",
    "                try:\n",
    "                    del train_X\n",
    "                    del train_Y\n",
    "                except:\n",
    "                    pass\n",
    "                test_X, test_Y = read_and_random_undersampling_dataset(f'{WORKING_DIRECTORY}Data/CODE-15', 'test'\n",
    "                                                                          , dataset_type = domena['dataset_type']\n",
    "                                                                          , undersampling = False\n",
    "                                                                          , return_numpy_copy = True\n",
    "                                                                          , X_post_processing = domena['X_post_processing']\n",
    "                                                                        )\n",
    "                print('test dataset is read')\n",
    "                atest_X, atest_Y  = read_and_random_undersampling_dataset(f'{WORKING_DIRECTORY}Data/CODE-15', 'atest'\n",
    "                                                                          , dataset_type = domena['dataset_type']\n",
    "                                                                          , undersampling = False\n",
    "                                                                          , return_numpy_copy = True\n",
    "                                                                          , X_post_processing = domena['X_post_processing']\n",
    "                                                                         )\n",
    "                print('test gold standart is read')      \n",
    "                test_Y = np.array(test_Y, dtype='float32')            \n",
    "                atest_Y = np.array(atest_Y, dtype='float32') \n",
    "\n",
    "                test_labels = test_Y[:, task] \n",
    "                atest_labels = atest_Y[:, task] \n",
    "            \n",
    "                try:\n",
    "                    test_prediction = clf.predict(test_X)\n",
    "                except: \n",
    "                    test_prediction = clf.predict(test_X.reshape(test_X.shape[0], -1))\n",
    "                try:\n",
    "                    atest_prediction = clf.predict(atest_X)\n",
    "                except: \n",
    "                    atest_prediction = clf.predict(atest_X.reshape(atest_X.shape[0], -1))\n",
    "\n",
    "                duration = duration_delta.total_seconds()\n",
    "                try:\n",
    "                    test_precision, test_recall, test_treshold = precision_recall_curve(test_labels\n",
    "                                                                       , test_prediction\n",
    "                                                                     )\n",
    "                    test_f1_array = np.nan_to_num(2 * test_precision * test_recall / (test_precision + test_recall))\n",
    "\n",
    "                    th = test_treshold[np.argmax(test_f1_array)-1]                    \n",
    "\n",
    "                    test_TP = (test_prediction > th)*test_labels\n",
    "                    test_FP = (test_prediction > th)*(1-test_labels)\n",
    "                    test_FN = (test_prediction <= th)*test_labels\n",
    "                    test_TN = (test_prediction <= th)*(1-test_labels)\n",
    "\n",
    "                    test_f1 = np.sum(test_TP) / (np.sum(test_TP) + 0.5*(np.sum(test_FP) + np.sum(test_FN)))\n",
    "                except:\n",
    "                    th = 0 \n",
    "\n",
    "                    test_TP = (test_prediction > th)*test_labels\n",
    "                    test_FP = (test_prediction > th)*(1-test_labels)\n",
    "                    test_FN = (test_prediction <= th)*test_labels\n",
    "                    test_TN = (test_prediction <= th)*(1-test_labels)\n",
    "                    \n",
    "                    test_f1 = -1\n",
    "                \n",
    "                try:\n",
    "                    atest_precision, atest_recall, atest_treshold = precision_recall_curve(atest_labels\n",
    "                                                                   , atest_prediction\n",
    "                                                                 )\n",
    "                    atest_f1_array = np.nan_to_num(2 * atest_precision * atest_recall / (atest_precision + atest_recall))\n",
    "\n",
    "                    th = atest_treshold[np.argmax(atest_f1_array)-1]                    \n",
    "\n",
    "                    atest_TP = (atest_prediction > th)*atest_labels\n",
    "                    atest_FP = (atest_prediction > th)*(1-atest_labels)\n",
    "                    atest_FN = (atest_prediction <= th)*atest_labels\n",
    "                    atest_TN = (atest_prediction <= th)*(1-atest_labels)\n",
    "\n",
    "                    atest_f1 = np.sum(atest_TP) / (np.sum(atest_TP) + 0.5*(np.sum(atest_FP) + np.sum(atest_FN)))\n",
    "                except:\n",
    "                    th = 0 \n",
    "\n",
    "                    atest_TP = (atest_prediction > th)*atest_labels\n",
    "                    atest_FP = (atest_prediction > th)*(1-atest_labels)\n",
    "                    atest_FN = (atest_prediction <= th)*atest_labels\n",
    "                    atest_TN = (atest_prediction <= th)*(1-atest_labels)\n",
    "                    \n",
    "                    atest_f1 = -1\n",
    "                              \n",
    "                with open(metrics_file, 'a') as f:\n",
    "                    f.write( f'{cl_name};{dm_name};{task};{run};{duration};test;{test_f1};{np.sum(test_TP)};{np.sum(test_FP)};{np.sum(test_FN)};{np.sum(test_TN)}\\n')  \n",
    "                    f.write( f'{cl_name};{dm_name};{task};{run};{duration};atest;{atest_f1};{np.sum(atest_TP)};{np.sum(atest_FP)};{np.sum(atest_FN)};{np.sum(atest_TN)}\\n')   \n",
    "                    \n",
    "                print(f'Clasifier {cl_name}, domena {dm_name}, task {task}, train_duration {duration}, run {run}: F1_test = {test_f1}, F1_atest = {atest_f1}')\n",
    "                \n",
    "                del clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856138b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.concatenate([[0], atest_treshold]), atest_f1_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec500c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "th = atest_treshold[np.argmax(atest_f1_array)-1]\n",
    "print(f'treshold = {th}')\n",
    "\n",
    "TP = (atest_prediction > th)*atest_labels\n",
    "FP = (atest_prediction > th)*(1-atest_labels)\n",
    "FN = (atest_prediction <= th)*atest_labels\n",
    "TN = (atest_prediction <= th)*(1-atest_labels)\n",
    "\n",
    "f1 = np.sum(TP) / (np.sum(TP) + 0.5*(np.sum(FP) + np.sum(FN)))\n",
    "print(f'F1_calk = {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c94cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
